{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question 7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Od3e9ljouIg6BWqugYPOwfCEA3-ZY07g",
      "authorship_tag": "ABX9TyNyxa0OoiHN+7WE9Q3QUZkf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanePai/Neural_Networks-Assignment-2/blob/main/Question_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0cJLxNsSxCk",
        "outputId": "0a90a86e-7afb-4dd5-b8de-92e6e0ff13df"
      },
      "source": [
        "%cd \"/content/drive/MyDrive/NNFL/Assignment 2\"\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/104/Assignment 2\n",
            "assignment2.pdf  data55.xlsx  input_a2.mat  label.mat\n",
            "class_label.mat  data5.mat    input.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYiWkY2A8AQS"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from sklearn.preprocessing import normalize\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix as cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4chq_amaN5ye"
      },
      "source": [
        "#Load data, shuffle and normalize\n",
        "mat_contents = loadmat('data5.mat')\n",
        "data = mat_contents['x']\n",
        "np.random.shuffle(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOd82655OiNe"
      },
      "source": [
        "def init_data():\n",
        "    X = np.array(data[ : , :-1], dtype = float)\n",
        "    y = np.array(data[ : , -1], dtype = int)\n",
        "    X = normalize(X, axis = 0)\n",
        "    return X, y\n",
        "\n",
        "\n",
        "X, y_ = init_data()\n",
        "y = np.zeros((len(y_), 2))\n",
        "for i in range(len(y_)):\n",
        "    if y_[i]==1:\n",
        "        y[i,1] = 1.0\n",
        "    elif y_[i]==0:\n",
        "        y[i,0] = 1.0\n",
        "\n",
        "\n",
        "X_train, y_train = X[ :int(0.7 * len(X))], y[ :int(0.7 * len(X))]\n",
        "X_val, y_val = X[ int(0.7 * len(X)): ], y[ int(0.7 * len(X)): ]\n",
        "\n",
        "alpha = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDXv7LoHOkCe"
      },
      "source": [
        "#Sigmoid function\n",
        "def sigmoid(x, derivative=False):\n",
        "        if (derivative == True):\n",
        "            return x * (1 - x)\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "#Tanh function\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "#Cost function\n",
        "def calc_cost(NN,x ,y):\n",
        "    \n",
        "    cost = 0\n",
        "    for i in range(len(x)):\n",
        "        x_ = np.reshape(x[i], (len(x[i]), 1))\n",
        "        cost += 0.5 / len(x) * np.sum((y[i] - NN.forward_pass(x_)) ** 2)\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYaPZOd6SqVa"
      },
      "source": [
        "#Neural network class\n",
        "class NeuralNetwork(object):\n",
        "    def __init__(self, sizes):\n",
        "        \n",
        "        self.num_layers = len(sizes)\n",
        "        self.sizes = sizes\n",
        "        self.W = {}\n",
        "        self.a = {}\n",
        "        self.b = {}\n",
        "        \n",
        "        #Initialize Weights\n",
        "        for i in range(1, self.num_layers):\n",
        "            self.W[i] = np.random.randn(self.sizes[i-1], self.sizes[i])\n",
        "            \n",
        "        #Initialize biases\n",
        "        for i in range(1, self.num_layers):\n",
        "            self.b[i] = np.random.randn(self.sizes[i], 1)\n",
        "        \n",
        "        #Initialize activations\n",
        "        for i in range(1, self.num_layers):\n",
        "            self.a[i] = np.zeros([self.sizes[i], 1])\n",
        "        \n",
        "    #Forward pass to compute scores\n",
        "    def forward_pass(self, X):\n",
        "        \n",
        "        self.a[0] = X\n",
        "        \n",
        "        for i in range(1, self.num_layers):\n",
        "            self.a[i] = sigmoid(np.dot(self.W[i].T, self.a[i-1]) + self.b[i])\n",
        "\n",
        "        return self.a[self.num_layers-1] \n",
        "    \n",
        "    #Backward pass to update weights\n",
        "    def backward_pass(self, X, Y, output):\n",
        "        \n",
        "        self.d = {}\n",
        "        self.d_output = (Y - output) * sigmoid(output, derivative=True)\n",
        "        self.d[self.num_layers-1] = self.d_output\n",
        "        \n",
        "        #Derivatives of the layers\n",
        "        for i in range(self.num_layers-1, 1, -1):\n",
        "            self.d[i-1] = np.dot(self.W[i], self.d[i]) * sigmoid(self.a[i-1], derivative=True)\n",
        "        \n",
        "        #Updating weights\n",
        "        for i in range(1, self.num_layers-1):\n",
        "            self.W[i] += alpha * np.dot(self.a[i-1], self.d[i].T)\n",
        "            \n",
        "        #Updating biases\n",
        "        for i in range(1, self.num_layers-1):\n",
        "            self.b[i] += alpha * self.d[i]\n",
        "\n",
        "    #Training helper function   \n",
        "    def train(self, X, Y):\n",
        "        X = np.reshape(X, (len(X), 1))\n",
        "        output = self.forward_pass(X)\n",
        "        self.backward_pass(X, Y, output)\n",
        "\n",
        "    #Get weights    \n",
        "    def get_W(self):\n",
        "        return self.W\n",
        "    \n",
        "    #Load specified weights\n",
        "    def load_W(self, W):\n",
        "        self.W = W\n",
        "\n",
        "    #Scores computation for given input    \n",
        "    def get_a(self, x):\n",
        "        x = np.reshape(x, (len(x), 1))\n",
        "        self.forward_pass(x)\n",
        "        return self.a\n",
        "    \n",
        "    #Helper function for autoencoder chaining\n",
        "    def load_a(self, a):\n",
        "        self.a = a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9uKbhbzCRs4",
        "outputId": "203b536f-e4ba-482c-854a-c1ef4412b663"
      },
      "source": [
        "#Initialization\n",
        "autoencoder1 = NeuralNetwork([72, 60, 72])\n",
        "autoencoder2 = NeuralNetwork([60,40,60])\n",
        "print(\"Autoencoder 1 Pre-Training\")\n",
        "#Autoencoder 1 pre-training\n",
        "for i in range(500):\n",
        "    for j, row in enumerate(X_train):\n",
        "        row = np.reshape(row, (72,1))\n",
        "        autoencoder1.train(row, row)\n",
        "        \n",
        "    cost = calc_cost(autoencoder1, X_train, X_train)\n",
        "    if (i+1)%100 == 0:\n",
        "        print(f\"Epoch {i+1}, Cost {cost}\")\n",
        "    \n",
        "autoencoder2_input = []\n",
        "\n",
        "for row in X_train:\n",
        "    autoencoder2_input.append(autoencoder1.get_a(row)[1])\n",
        "\n",
        "autoencoder2_input = np.array(autoencoder2_input)\n",
        "print(\"===========================\")\n",
        "print(\"Autoencoder 2 Pre-Training\")\n",
        "#Autoencoder 2 pre-training\n",
        "for i in range(500):\n",
        "    for j, row in enumerate(autoencoder2_input):\n",
        "        row = np.reshape(row, (60,1))\n",
        "        autoencoder2.train(row, row)\n",
        "        \n",
        "    cost = calc_cost(autoencoder2, autoencoder2_input, autoencoder2_input)\n",
        "    if (i+1)%100 == 0:\n",
        "        print(f\"Epoch {i+1}, Cost {cost}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Autoencoder 1 Pre-Training\n",
            "Epoch 100, Cost 372.09203520113647\n",
            "Epoch 200, Cost 372.0658432344584\n",
            "Epoch 300, Cost 372.05983340422824\n",
            "Epoch 400, Cost 372.0585230556606\n",
            "Epoch 500, Cost 372.0587797347227\n",
            "===========================\n",
            "Autoencoder 2 Pre-Training\n",
            "Epoch 100, Cost 5.760830264321385\n",
            "Epoch 200, Cost 5.7606821147182705\n",
            "Epoch 300, Cost 5.76061414935539\n",
            "Epoch 400, Cost 5.760571632624941\n",
            "Epoch 500, Cost 5.760540489032467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3A3_N_FCUku"
      },
      "source": [
        "#ELM Input\n",
        "elm_input = []\n",
        "for row in autoencoder2_input:\n",
        "    elm_input.append(autoencoder2.get_a(row)[1])   \n",
        "elm_input = np.array(elm_input)\n",
        "\n",
        "#ELM Params\n",
        "elm_neurons = 300\n",
        "output_neurons = 2\n",
        "W_elm = np.random.randn(elm_input.shape[1], elm_neurons)\n",
        "\n",
        "#ELM Training\n",
        "np.random.seed(1)\n",
        "elm_input = np.reshape(elm_input, (1503, 40))\n",
        "H = np.matmul(elm_input, W_elm)\n",
        "H = tanh(H)\n",
        "H_inv = np.linalg.pinv(H)\n",
        "W_final = np.matmul(H_inv, y_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgCKVTckCaxu"
      },
      "source": [
        "#Testing on validation set\n",
        "\n",
        "#Autoencoder 1 forward pass\n",
        "layer1_out = []\n",
        "\n",
        "for i, row in enumerate(X_val):\n",
        "    act = autoencoder1.get_a(row)[1]\n",
        "    layer1_out.append(act)\n",
        "    \n",
        "layer1_out = np.array(layer1_out)\n",
        "layer1_out = np.reshape(layer1_out, (645, 60))\n",
        "\n",
        "#Autoencoder 2 forward pass\n",
        "layer2_out = []\n",
        "\n",
        "for i, row in enumerate(layer1_out):\n",
        "    act = autoencoder2.get_a(row)[1]\n",
        "    layer2_out.append(act)\n",
        "    \n",
        "layer2_out = np.array(layer2_out)\n",
        "layer2_out = np.reshape(layer2_out, (645, 40))\n",
        "\n",
        "#ELM forward pass\n",
        "H_T = np.matmul(layer2_out, W_elm)\n",
        "H_T = tanh(H_T)\n",
        "y_pred = np.matmul(H_T, W_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj-UVANlB3Ve",
        "outputId": "102bda42-b9ab-4e88-d755-00e0849f795f"
      },
      "source": [
        "a = [np.argmax(y_pred[i]) for i in range(len(y_pred))]\n",
        "b = [np.argmax(y_val[i]) for i in range(len(y_val))]\n",
        "\n",
        "confmat = cm(b,a)\n",
        "\n",
        "Accuracy = (confmat[0][0]+confmat[1][1])/len(y_pred)\n",
        "Sensitivity = (confmat[1][1])/(confmat[1][0] + confmat[1][1])\n",
        "Specificity = (confmat[0][0])/(confmat[0][0] + confmat[0][1])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confmat)\n",
        "print(\"\\n\")\n",
        "print(f\"Accuracy: {Accuracy}\\nSensitivity: {Sensitivity}\\nSpecificity: {Specificity}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[275  50]\n",
            " [ 63 257]]\n",
            "\n",
            "\n",
            "Accuracy: 0.8248062015503876\n",
            "Sensitivity: 0.803125\n",
            "Specificity: 0.8461538461538461\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}